LLM is a prediction engine or machine, that **predicts the next word** from a sequence of words. Remember it nevers chooses a single word, it always predicts a distribution of words, and then samples from that distribution.

We can use this point and set up the LLM to predict the right sequence of words, by providing it with a **prompt** that is as close as possible to the desired output.

>> Token: A token is a piece of text that the LLM uses to understand and generate language. It can be a word, part of a word, or even punctuation. The LLM processes text by breaking it down into these tokens, which allows it to analyze and generate language more effectively.
